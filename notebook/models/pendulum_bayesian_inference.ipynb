{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Set up simple pendulum problem\n# Bayesian Inference on a Pendulum using Turing.jl\n### Vaibhav Dixit"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "using DiffEqBayes, OrdinaryDiffEq, RecursiveArrayTools, Distributions, Plots, StatsPlots"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's define our simple pendulum problem. Here our pendulum has a drag term `ω`\nand a length `L`.\n\n![pendulum](https://user-images.githubusercontent.com/1814174/59942945-059c1680-942f-11e9-991c-2025e6e4ccd3.jpg)\n\nWe get first order equations by defining the first term as the velocity and the\nsecond term as the position, getting:"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "function pendulum(du,u,p,t)\n    ω,L = p\n    x,y = u\n    du[1] = y\n    du[2] = - ω*y -(9.8/L)*sin(x)\nend\n\nu0 = [1.0,0.1]\ntspan = (0.0,10.0)\nprob1 = ODEProblem(pendulum,u0,tspan,[1.0,2.5])"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Solve the model and plot\n\nTo understand the model and generate data, let's solve and visualize the solution\nwith the known parameters:"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "sol = solve(prob1,Tsit5())\nplot(sol)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's the pendulum, so you know what it looks like. It's periodic, but since we\nhave not made a small angle assumption it's not exactly `sin` or `cos`. Because\nthe true dampening parameter `ω` is 1, the solution does not decay over time,\nnor does it increase. The length `L` determines the period.\n\n### Create some dummy data to use for estimation\n\nWe now generate some dummy data to use for estimation"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "t = collect(range(1,stop=10,length=10))\nrandomized = VectorOfArray([(sol(t[i]) + .01randn(2)) for i in 1:length(t)])\ndata = convert(Array,randomized)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see what our data looks like on top of the real solution"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "scatter!(data')"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "This data captures the non-dampening effect and the true period, making it\nperfect to attempting a Bayesian inference.\n\n### Perform Bayesian Estimation\n\nNow let's fit the pendulum to the data. Since we know our model is correct,\nthis should give us back the parameters that we used to generate the data!\nDefine priors on our parameters. In this case, let's assume we don't have much\ninformation, but have a prior belief that ω is between 0.1 and 3.0, while the\nlength of the pendulum L is probably around 3.0:"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "priors = [Uniform(0.1,3.0), Normal(3.0,1.0)]"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally let's run the estimation routine from DiffEqBayes.jl using the Turing.jl backend"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "bayesian_result = turing_inference(prob1,Tsit5(),t,data,priors;num_samples=10_000,\n                                   syms = [:omega,:L])"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice that while our guesses had the wrong means, the learned parameters converged\nto the correct means, meaning that it learned good posterior distributions for the\nparameters. To look at these posterior distributions on the parameters, we can\nexamine the chains:"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "plot(bayesian_result)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "As a diagnostic, we will also check the parameter chains. The chain is the MCMC\nsampling process. The chain should explore parameter space and converge reasonably\nwell, and we should be taking a lot of samples after it converges (it is these\nsamples that form the posterior distribution!)"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "plot(bayesian_result, colordim = :parameter)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice that after awhile these chains converge to a \"fuzzy line\", meaning it\nfound the area with the most likelihood and then starts to sample around there,\nwhich builds a posterior distribution around the true mean."
      ],
      "metadata": {}
    }
  ],
  "nbformat_minor": 2,
  "metadata": {
    "language_info": {
      "file_extension": ".jl",
      "mimetype": "application/julia",
      "name": "julia",
      "version": "1.1.0"
    },
    "kernelspec": {
      "name": "julia-1.1",
      "display_name": "Julia 1.1.0",
      "language": "julia"
    }
  },
  "nbformat": 4
}
